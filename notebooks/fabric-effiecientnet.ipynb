{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9014918,"sourceType":"datasetVersion","datasetId":5408843},{"sourceId":9080830,"sourceType":"datasetVersion","datasetId":5478601}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import random_split, DataLoader\n\n# Set up paths to your data\nnum_classes = 18  # Set this to the number of classes you have\nbatch_size = 32\nnum_epochs = 100\n\n\n# data_dir = '/kaggle/input/pattern-recognition/pattern-recognition'\ndata_dir = '/kaggle/input/fabric-romo/romo'\n\ntransform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ndataset = ImageFolder(data_dir+'/train', transform=transform)\nimg, label = dataset[0]\nprint(img.size(), label)\nprint(dataset.classes)\n\n\nprint(len(dataset))\ntotal_size = len(dataset)\nval_size = int(0.3 * total_size)\ntrain_size = len(dataset) - val_size\n\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)\n\n\n# Load the pre-trained EfficientNet model\nmodel = models.efficientnet_b0(pretrained=True)\n\n# Modify the classifier layer to match the number of classes\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n\n# Use GPU if available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n\n# Validation loop\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Validation Accuracy: {100 * correct / total}%')\n\n# Fine-tuning the model (optional)\nfor param in model.features.parameters():\n    param.requires_grad = False\n\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\n\n# Training loop for fine-tuning\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n    print(f'Fine-tuning Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n\n# Validation loop after fine-tuning\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Validation Accuracy after Fine-tuning: {100 * correct / total}%')\n\ntorch.save(model.state_dict(), \"/kaggle/working/model.pth\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T04:59:07.947299Z","iopub.execute_input":"2024-08-05T04:59:07.947690Z","iopub.status.idle":"2024-08-05T05:01:15.464254Z","shell.execute_reply.started":"2024-08-05T04:59:07.947648Z","shell.execute_reply":"2024-08-05T05:01:15.462952Z"},"trusted":true},"execution_count":null,"outputs":[]}]}